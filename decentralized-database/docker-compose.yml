version: '3.8'

services:
  ipfs:
    image: ipfs/go-ipfs:latest
    volumes:
      - ./data/ipfs:/data/ipfs
    ports:
      - "4001:4001"
      - "8081:8080"
      - "5001:5001"

  hadoop-namenode:
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./config/hadoop.conf
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    volumes:
      - ./logs/hadoop-namenode:/opt/hadoop/logs

  hadoop-datanode:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./config/hadoop.conf
    volumes:
      - ./logs/hadoop-datanode:/opt/hadoop/logs

  resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
       - 8088:8088
    env_file:
      - ./config/hadoop.conf
    volumes:
      - ./logs/resourcemanager:/opt/hadoop/logs

  nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config/hadoop.conf
    volumes:
      - ./logs/nodemanager:/opt/hadoop/logs

  spark-master:
    image: apache/spark:4.0.0-preview2
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    volumes:
      - ./jars/postgresql-42.6.0.jar:/opt/spark/jars/postgresql-42.6.0.jar
      - ./config/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    ports:
      - "8080:8080"
      - "7077:7077"

  spark-worker:
    image: apache/spark:4.0.0-preview2
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_MASTER=spark://spark-master:7077
    volumes:
      - ./jars/postgresql-42.6.0.jar:/opt/spark/jars/postgresql-42.6.0.jar
      - ./config/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    depends_on:
      - spark-master

  postgres:
    image: postgres
    container_name: postgres
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive"]
      interval: 10s
      timeout: 5s
      retries: 5

  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    depends_on:
      postgres:
        condition: service_healthy
      hadoop-namenode:
        condition: service_started
    environment:
      HADOOP_CONF_DIR: /opt/hive/conf
      HIVE_DB: postgres
      DB_DRIVER: postgres
      HIVE_VERBOSE: VERBOSE
      HADOOP_OPTS: "-Dlog4j.configuration=file:/opt/hive/conf/log4j.properties -Dlog4j.debug=true"
    volumes:
      - ./config/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./jars/postgresql-42.6.0.jar:/opt/hive/lib/postgresql-42.6.0.jar
      - ./config/log4j.properties:/opt/hive/conf/log4j.properties
      - ./config/log4j2.properties:/opt/hive/conf/log4j2.properties
    ports:
      - "9083:9083"
    entrypoint: 
      - /bin/bash
      - -c
      - |
        echo "Debugging file locations:"
        ls -l /opt/hive/conf/
        echo "Contents of log4j2.properties:"
        cat /opt/hive/conf/log4j2.properties
        echo "Initializing schema..."
        /opt/hive/bin/schematool -dbType postgres -initOrUpgradeSchema
        echo "Starting Hive Metastore..."
        /opt/hive/bin/hive --service metastore --verbose
    healthcheck:
      test: ["CMD", "/opt/hive/bin/schematool", "-dbType", "postgres", "-info"]
      interval: 30s
      timeout: 10s
      retries: 3

  hive-server:
    image: apache/hive:4.0.0
    container_name: hive-server
    depends_on:
      hive-metastore:
        condition: service_healthy
    environment:
      HIVE_METASTORE_URI: thrift://hive-metastore:9083
      HADOOP_CONF_DIR: /opt/hive/conf
      HIVE_DB: postgres
      DB_DRIVER: postgres
      HADOOP_OPTS: "-Dlog4j.configuration=file:/opt/hive/conf/log4j.properties -Dlog4j.debug=true"
    volumes:
      - ./config/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./jars/postgresql-42.6.0.jar:/opt/hive/lib/postgresql-42.6.0.jar
      - ./config/log4j2.properties:/opt/hive/conf/log4j2.properties
    ports:
      - "10000:10000"
    entrypoint: 
      - /bin/bash
      - -c
      - |
        echo "===== Debugging Hive Server2 Setup ====="
        echo "Current directory: $(pwd)"
        echo "Listing Hive configuration directory:"
        ls -l /opt/hive/conf/
        echo "Contents of hive-site.xml:"
        cat /opt/hive/conf/hive-site.xml
        echo "Contents of log4j2.properties:"
        cat /opt/hive/conf/log4j2.properties
        echo "Checking Hadoop configuration:"
        ls -l $HADOOP_CONF_DIR
        echo "Checking connectivity to Hive Metastore:"
        nc -zv hive-metastore 9083
        echo "Checking Postgres JDBC driver:"
        ls -l /opt/hive/lib/postgresql-42.6.0.jar
        echo "Starting Hive Server2 with verbose logging:"
        hive --service hiveserver2
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "10000"]
      interval: 30s
      timeout: 10s
      retries: 3

  node-base:
    image: decentralized-db:latest
    volumes:
      - ./src:/app
      - ./config:/config
    environment:
      - HADOOP_CONF_DIR=/config
      - SPARK_CONF_DIR=/config
      - HIVE_CONF_DIR=/config
    depends_on:
      - spark-master
      - hive-metastore

  node-master:
    extends:
      service: node-base
    command: ["/bin/bash", "-c", "/app/scripts/init_node.sh master && /app/scripts/join_network.sh && python /app/master/control_panel/app.py"]
    ports:
      - "5000:5000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - ipfs
      - hadoop-namenode
      - spark-master
      - hive-server

  node-worker:
    extends:
      service: node-base
    command: ["/bin/bash", "-c", "/app/scripts/init_node.sh worker && /app/scripts/join_network.sh && python /app/worker/worker.py"]